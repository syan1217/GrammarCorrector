{"cells":[{"cell_type":"code","source":["# Colab: Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","#place this tutorial.ipynb in your google drive under below directories (of course you need to create these folders first!):\n","#/SideProjects/LLM/SgLang/\n","%cd '/content/drive/MyDrive/SideProjects/LLM/SgLang/'"],"metadata":{"id":"Cq8Q913e68eG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import all necassary packages:\n","! pip install --upgrade pip\n","! pip install \"sglang[all]\"\n","! pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/\n","! pip install triton"],"metadata":{"id":"Cwwmtyo2HGhj","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#log into hugging face: this is used to connect with the selected language model\n","!huggingface-cli login"],"metadata":{"id":"YBogbv23s1sO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#used to running the server (you can choose any, but I recommend start with the parameter with 8b!) in the background, so that we can run the next cell in the colab\n","#we need to wait one or two minutes before running the next cell!\n","import subprocess\n","subprocess.Popen(['python', '-m', 'sglang.launch_server', '--model-path', 'meta-llama/Meta-Llama-3-8B-Instruct', '--port', '30000'])\n"],"metadata":{"id":"ZZT6iPxQtDCj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check if the server is running or not:\n","!ps -aux | grep sglang.launch_server"],"metadata":{"id":"GxVuqpIDtW0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyngrok\n","!ngrok authtoken '' # Get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken"],"metadata":{"collapsed":true,"id":"SKqItrGmKmh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, render_template, request, jsonify\n","from sglang import function, system, user, assistant, gen, set_default_backend, RuntimeEndpoint\n","from pyngrok import ngrok #run it through ngrok!\n","\n","app = Flask(__name__)\n","\n","# Define the grammar correction function\n","@function\n","def grammar_corrector(s, text_to_correct, conversation_state=None, user_request=None):\n","    if conversation_state is None:\n","        s += system(\"You are a grammar correction assistant. Correct the following text to proper English. You just need to generate the final output! No need to show the errors\")\n","        s += user(f\"Original text: {text_to_correct}\")\n","    else:\n","        s += system(f\"Continuing conversation. The last corrected text was: '{conversation_state}'.\")\n","        s += user(f\"User's follow-up request: {user_request}\")\n","\n","    s += assistant(gen(\"corrected_text\", max_tokens=256))\n","\n","set_default_backend(RuntimeEndpoint(\"http://localhost:30000\"))\n","\n","conversation_state = None\n","\n","@app.route('/')\n","def index():\n","    return render_template('index.html')  # Renders the HTML file located in the templates folder\n","\n","@app.route('/chat', methods=['POST'])\n","def chat():\n","    global conversation_state\n","    user_input = request.json['message']\n","\n","    # Run the grammar corrector\n","    state = grammar_corrector.run(\n","        text_to_correct=user_input,\n","        conversation_state=conversation_state,\n","        user_request=user_input\n","    )\n","\n","    # Extract the corrected text\n","    corrected_text = state[\"corrected_text\"]\n","    conversation_state = corrected_text\n","\n","    return jsonify({'response': corrected_text})\n","\n","\n","\n","if __name__ == '__main__':\n","    # Open an ngrok tunnel to the Flask app\n","    public_url = ngrok.connect(5000)\n","    print(f\" * ngrok tunnel available at: {public_url}\")\n","\n","    # Run the Flask app\n","    app.run()\n"],"metadata":{"id":"uNnX9bNtHb1o"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"11ccMZ3iwXo054SeYSge6_k2IHM5lXJTt","timestamp":1685999055998}],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}